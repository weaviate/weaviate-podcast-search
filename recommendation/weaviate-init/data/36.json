[
    {
        "speaker": "Connor Shorten",
        "content": "Hey, everyone, I'm super excited about this Weaviate podcast. We have Langchain founder Harrison Chase and Weaviate CEO and co-founder Bob van Luijt. So guys, thanks so much for joining the podcast. ",
        "podNumber": 36
    },
    {
        "speaker": "Bob van Luijt",
        "content": "Thanks, man. Looking forward to this conversation. ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "Thanks for having me, guys. Really excited to be here. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "Awesome. Well, I'm just so excited to dive into it. Harrison, could we start with the story of like the origin story of Langchain, like how you created this? Yeah, I mean, it started really kind of innocently and innocuously. I was just chatting with the but so, you know, everyone's into language models these days. Everyone's building applications. And so when I first started chatting with folks, and this is back in like September, October, people were still into it, not to the extent they are today. But there was a lot of people playing around and messing around and building applications. And I chatted with a bunch of them at meetups. I had some friends building stuff. Sam Whitmore, shout out to her, was building an awesome application. And so really got to like know them and chat with them about their use cases. And basically just saw like a few common kind of like abstractions, things that were happening, factored those out, put those in a Python package, very kind of like just engineer, you know, factor stuff out, put it in there, and put it out there, put it out to the world and got got a positive response. And so kept on adding stuff in, kept on refactoring as you know, the abstractions that I thought I first saw were, of course, wrong. And so those kind of like evolved over time. But yeah, basically just started off by chatting with a bunch of folks and pulling out common abstractions into a Python package. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "Brilliant. Maybe so we could start with kind of maybe the first abstraction that helped me understand link chain was kind of the sequential chains. Like, you know, you have the output of the language model as the input to the next call to the language model. Could maybe start with describing the sequential chains? ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "Yeah, absolutely. I think so. The idea of chaining is basically breaking up calls to language models in multiple steps. And not only calls to language models, but to other things, actually. And so I think actually most of the examples that I first added were like language model, and then other thing and then language model and basically chaining the results of them together in a way where you can you did some iterative stuff. And so to make this concrete with an example, one of one of the things that I first added was based on a paper by Off Press, self ask with search. So basically, you'd ask a question and the examples in this paper were kind of like multi hop questions. So it wasn't just like a simple answer. And these are cases where language models are known to kind of like not perform super well. And so the self ask with search paradigm is you first kind of like think about what intermediate questions you need to answer. So I think like the example used in the paper is like, what is the hometown of the current US Open champion? And so like, if we're if we're thinking about that intuitively, like what would we do as humans first would think about who the current US Open champion is, and then would figure out where his hometown is. And so basically, the idea of chaining was to break those down into exactly those steps. So the language model should hopefully know that it first needs to think about who the current US Open champion is, figure that out. And then it needs to think about where he's from and figure that out. And you could do that with, you could do that with a single passable language model. The thing that's, the thing that's interesting, and the thing that caught my attention was basically the idea of combining the language model with Google search. Because if you're asking about the current US Open champion, the language model was trained on data up to 2021, or something like that wouldn't know the information. And so basically, use a language model to ask the intermediate question, you then pass that question to a search API, you get back a result, and then you basically keep on going from there. And so the idea of the idea of chaining that really stuck out. And this is a little bit different than the sequential chains that you brought up. But I think it's, I think it's more interesting, to be honest. So I think it's the idea of chaining language models to determine to figure out what information they need to look up, getting that information from a separate, more, more accurate, more reliable, more up to date source, and then plugging that back in and letting it continue on its merry way. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "Oh, yeah, incredible. And Bob and I recorded our generate module podcast. And Bob, you could hop in more on sort of just how you're seeing this kind of, you know, language model calling the search database and you know, from Google search to Weaviate search.",
        "podNumber": 36
    },
    {
        "speaker": "Bob van Luijt",
        "content": "Yeah, it's so it's so funny that you bring it up, because that's exactly what I wanted to say, because the there were like these two things, sometimes you have like these multiple things coming together, right? So one is exactly when you started with Langchain, I was looking into like, so what is he doing? And it's like, oh, I got it. And then there was also that article that I was like, when people say like, Okay, hey, we can hook this up to Google search. I was like, you can also hook it up to a vector search engine, right? And do this stuff with your own data. So that was why I was so super, you know, I was super excited about, you know, about what you're working on Harrison. Because I was like, you know, this is like just a beautiful synergy of all these things coming together where we really use natural language to or create a change or have the database for like, you know, large amounts of data. And that's just, I had the exact same, I was looking at the exact same thing. And when I saw hooking it up to Google search, and I don't remember Connor, I think you shared that first article with me. But when I saw that, I was like, yes, that's what we can do. And then everything came together. And then you started with Langchain. And we're looking at what we could do there. It was just it was just super, you know, super exciting. So I had the exact same thing. ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "And and to your point, Bob, like, I actually think it's I think it's more interesting to hook it up to your Weaviate database or your own internal data, because that's just more like unique to you. And that's more distinct to you. Like anyone can hook it up to Google search, right? Anyone can hook it up to Wolfram Alpha, but like your your documents, your data that are in your vector database, your weaviate database, connecting it with that, like that, I think allows you to build like a differentiated and unique kind of like chatbot or question answering or whatever kind of like experience. ",
        "podNumber": 36
    },
    {
        "speaker": "Bob van Luijt",
        "content": "Exactly. And I think why it's interesting to do that with like new types of vector databases like Weaviate or for that matter, also Wolfram, right? So it is that it has this natural language interface. So and when I recorded the podcast with, together with Connor. So while we're recording, we have not released the module yet. But when this podcast sees the light of day, people will know about it. Right. So the is that we're moving towards a how should I say to to a way of interacting with the database, not with like precise queries and precise answers like you need to have a keyword that matches your database versus a result that you're getting from the database that must be stored in the database. But we can just you know, we can just have free associations in our database and we can even generate different results based on the tasks or the prompts that we're giving to our data. And I think that's just that that's super exciting. I just just talking about it and thinking about it just makes me like super exciting for the coming year. It's going to be it's going to be a cool year. ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "Yeah, I think like this natural language layer on top of like, whether it's whether it's a vector database or a structured SQL database or a Mongo database, any of that, I think that's really powerful and really interesting because it allows like people who don't know SQL or don't know how to write GraphQL to interact with these databases. And so, yeah, I'm really excited to see this kind of like unlock a lot of, you know, new people using using this stuff across a variety. ",
        "podNumber": 36
    },
    {
        "speaker": "Bob van Luijt",
        "content": "I agree. I agree. Yeah. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "Yeah, that's something that I thought was so exciting when I first saw LangChain is how the language model can control the database, like you just said, with the writing the GraphQL queries out or writing the SQL queries, writing graph database queries. So can we talk about that kind of orchestration layer where you say tell the language model, hey, you have like in Weaviate land, you have this class, you have this class, you have this class, this class contains like Weaviate blog posts, this documentation, this is the code base. And so it like chooses which information source to traverse. Maybe you can also talk about like SQL or like the Google search API or just other APIs, like all sorts of external data sources and how that's interfaced in LangChain. ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "Yeah, I think I'll maybe start with just a SQL database example, because I think that's maybe one that most people are familiar with it. But the ideas are common across other types of databases, whether structured or unstructured or vector or anything like that. And I'll start with like a simple example, but I think we'll see pretty quickly that it starts to get pretty complex. Okay. So at the most like simple example, the pipeline is basically you take in a natural language query, you then generate relevant SQL, and I'll come back to that in a little bit, but you generate relevant SQL, you then execute that SQL against the database, you get back the result, and then you pass that to the language model if desired and kind of like return like a human interpretable answer. And so yeah, like I think the example that we have in the documentation is like how many employees exist. And so it does like, it gets like the count of the number of rows in the employee table and then returns something to the user, like there are nine employees or something like that. Touching on the first part, like generating the relevant SQL query, as you were getting at, there's a lot of information that you actually need to put in to kind of do that correctly. So you need to kind of like put in information about all the tables that exist, and then not only the tables, but the columns as well. And if there are relationships between those columns, you need to input those as well. And so the prompt that you're constructing starts to get pretty complicated already. And so a lot of the value that LangChain provides is ways to like easily construct these prompts and then also like just like see what's going on. Like this is a complicated prompt, I'm already describing it, I already probably lost half the audience. And so like making it like really easy to see like what's going on and what it actually looks like. Okay, so that's like the simple use case, but there are a lot of like complexities. So what if there are just like too many tables and too many rows, or sorry, too many columns in those tables to put into the prompts, because there are contexts kind of like window length. What do you do then? And so one, another chain that we have in LangChain is basically a chain that first selects relevant tables, and then puts only those tables in the prompt. And so kind of like a simple idea, but basically the idea of like filtering down. So that's around like constructing the query. Then after like executing the query, what if the query is like incorrect syntax? What if it's kind of like references tables that don't exist? What do you do then? And so I think there's a few things that, to be honest, aren't in LangChain yet. They might be by the time this gets released, I think they're on our roadmap. One is the concept of kind of like output parsing or validators or guardrails. So like validating that things are valid in SQL syntax and stuff like that. Another idea is basically the idea of kind of like if it tries and it fails, just like passing that back to the language model and letting it learn from its mistakes. There's a really good example of this working from Riley Goodside, not with SQL, but with like a Python example, where he asks it to do a math problem. It tries to use like the math module, but it's not imported. And so if you allow it to kind of like correct its errors, it will see like import error math, not recognized, and then it will kind of like fix it the next time around. And so I think like things like that for SQL, for any type of database querying will be important as well. Yeah. So I think that's an overview of kind of like what's in LangChain currently and like stuff that we want to add because yeah, it gets a little complex a little quickly. ",
        "podNumber": 36
    },
    {
        "speaker": "Bob van Luijt",
        "content": "Just out of curiosity to build on top of that, because the focus now is mostly that you have like a language, right? LangChain. What do you think when it comes to like these multi-modal kind of models, right? So what do you think will happen there and how will LangChain potentially evolve with these kinds of models? Or do you have any thoughts on that? ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "Yeah. No, that's a really good question. I think, okay, so the simple answer is basically kind of like integrations we can already do, and there actually already are PRs for this to kind of like hook up kind of like multi-modal things on either end of the language model. So for example, like take an audio file, transcribe it, generate some stuff, generate some text. That's done by kind of like converting it into the text domain. So in that sense, it's somewhat multi-modal, but it's not like fully multi-modal. Another example of this kind of like quasi thing is like hooking it up to an image API or something. So there is a PR open to basically have a chain that first like takes in, you know, like, because all the image prompts are like really convoluted. Like that's like wizardry right there. So take in kind of like a simpler query, generate a more convoluted prompt, pass it to DALL-E or something, get back an image. So in that sense, I think there's already, there will shortly be kind of like multi-modal support in LangChain. More are involved than that, honestly, I don't know at the moment. I think, I know there have been a lot of more kind of like first class multi-modal models coming out. And so I think we need to look a little bit more carefully about how to integrate those. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "Yeah, so the thinking is like you would have an image captioning tool, that parses the image into text, and then it just easily flows into the text interface of the chatGPT and mostly. ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "Yeah, that's kind of how we're imagining things. That would be easiest for the current kind of like construction of LangChain for sure. And so I think that's what we'll do first. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "Yeah, I think that's such an exciting emerging thing of the, you know, like the multi-modal chatGPT style, large vision language model. I think that is definitely on the horizon I would, if I had to take a guess, I'd say that's within three months. ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "Yeah, I hope so. I'm excited to play around with it. I think, I think character AI has done some like multi-modal stuff as well. I think they have some multi-modal chat bots. So yeah, excited to see it more widespread. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "I was just going to say, yeah, I saw like DeepMind's Flamingo at NeurIPS is that already. ",
        "podNumber": 36
    },
    {
        "speaker": "Bob van Luijt",
        "content": "Yeah, so I just, it's like by middle of like a thought experiment. So the other day I was thinking about the following, right. So what I noticed, and that's something we are doing also with Weaviate and maybe that's also happening for like what you're working on Harrison is that I was thinking somehow we try to capture these things in like a traditional way of software engineering, right. So we say, okay, how do we write the technology to, you know, and then we get stuff back and then we get these complex chains in your case or in our case, like how will we represent the data? I was, if we just think about like two, three years from now, could it be the case that we're just interact with like software completely different because of these LLMs and what we're doing today. So to give you a very pragmatic example, the first time I interacted with a generative model, so quite some time ago, I needed to get used to the fact that I was not writing software so that I just could use natural language to give it an assignment that felt so unnatural to me, right. So I'm just curious, I actually both of you, how you guys see this because I'm, I just, I have like a feeling that we're still trying to shoehorn this into a traditional way of writing software, but that maybe in like a year, two years from now, that's just a completely different paradigm in how we create technology and, or how we interact database or how we chain things together. I'm, I'm just curious what you guys think about that. If you just, you know, kind of dream into the future, what this might look like. ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "Yeah, I, I think, I mean, it's a really good question, right? Like, that's like, I think the UX for all these things is kind of like what we're doing right now. I don't have any, I don't have any great answers. I think like one thing that, I mean, it kind of like in the vein of like, and this is a bit more on the like developer side of things, but on like the vein of like multi-modal stuff, like I think like, you know, right now, a lot of the stuff that we're, like when we're talking about ingesting data, right, for like PDFs, like right now we're transforming a PDF into like some text and then maybe we're like, you know, we're just like, we're just like, we're just like, we're just like, we're just like, we're just like transforming a PDF into like some text and then maybe like embedding that text or something like that, or transforming, yeah, doing like a caption on an image and embedding that caption or something like that. I think a lot of stuff will move towards just being like talking to each other and like embedding space basically and translating between that. But yeah, that, that's kind of a little bit separate than what you were asking. I don't, yeah, I don't, I mean, okay, so here's what, here's what I'll say around like the UX of actual products. I think they'll be like, look at Copilot. Like why does Copilot like work as kind of like a product? It works because it's in a situation where you don't need 100% accuracy. There's a human in the loop. And yeah, it's a bit, it's, it's kind of like working with you. And so I think like, you know, the, the common thing for products has been like Copilot for X, Copilot for X. And I think like the important part is like, it's, people are still getting used to working with these language models. The language models still aren't at like 99% accuracy or even close to that. So you need kind of this human in the loop and this like situations where it's okay to have lower accuracy. I think we'll start, I think as language models get better and we get more familiar, we'll start to go, we'll start to see more applications where there's less human in the loop and they're more automated. And they're in situations where you can have like higher accuracy or, or sorry. Yeah. Where yeah, where you can get a higher accuracy, where you need higher accuracy and it starts to unlock that. So yeah, you know, I don't have any great insights as to what the future will look like, but I think that is like one kind of like natural progression that, that, that we'll see. ",
        "podNumber": 36
    },
    {
        "speaker": "Bob van Luijt",
        "content": "Yeah, exactly. Because I, I was also thinking about this and I, I was trying to think back of like Weaviate, how we created it, like the origins of it. And I remember that had like this epiphany moment when I was at a, at a conference and we were talking about the semantic web and that there was like that some people in the audience were like annoyed because we humans couldn't agree on stuff. Right. So how we were structuring data and that this whole thing of these language models, not even large language, but just language models in general, right. Back then it was just glove, fast text, et cetera, that people started to think about, what if we don't have to do that anymore? And I think if you now, for example, fast forward to today. So for example, let's say that Connor and I, that we're like, we're working on a piece of code, right. And I make a mistake and say, Connor, it's not what, what mistake did I make? And Connor looks at it and say, Oh, you forgot like a semicolon or something. That I could imagine that we're moving towards a space where you have, you're almost running like pseudo code, but that the model says, Oh no, I gotcha. I know what you want to do. I'll just execute it. Right. I see where you're going. And I would not be surprised that that would just get to a natural language state of programming, which of course will come with certain rules and certain UX elements. I was listening to a podcast from the open, what's the name? The open source data podcast from Sam Ramji and he was interviewing Ben Lorica. And then Ben also said like, how will we get the rigor of software engineering into working with these language models? And I find that just super interesting because if we're, if we, and then we like, you better, we'll figure out how to do that, then it will become easier for people to interact with these models, but also write technology, software, right? So we just describe what you want and the model helps you to deploy it, to develop it. I would not be surprised that we will see things based on also what you're working on Harrison, that there will be like deploy a complex infrastructure by just describing it in natural language. And then the model figures out, oh, then I need to spin up a pod here and I need to do this over there and those kinds of things, right? Or design that you just have visual design, you just describe it and then it goes like, okay, gotcha. And it just figures that out. So I really hope that it also lowers the barrier for even more people to just write software and just create cool things. And I would not be surprised in like a year, two years from now, we're just, we're slowly moving towards, well, a natural language way of describing what we want the machines to do. And then they just, in combination with this model, they just figure it out and just do it. ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "Yeah. And I think there's been a lot of talk around like, you know, prompt engineering, like it is prompt engineering here to last. Like my take is it will kind of like converge to like what you're describing, like just as you would tell a human how to do something, you'll have to tell the language model how to do something. And so this to your point around this natural language interface for doing something, like, yeah, I think that's pretty realistic that we can get there. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "No, yeah. That kind of like, I think I really like the example that Harrison brought earlier quickly. I want to come back to that about like with the SQL code, how you check if it's correct kind of, and it makes it like, I'm so excited about this idea of like the language model would write code to run experiments, like run the experiments and then analyze the experiments. Could maybe kind of step into the technical and like, how will it this look, how will it check the correctness and then flow in the LangChain syntax? ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "Yeah. And I mean, Copilot had a really cool demo of this at one of the Microsoft conferences where they asked it to write a problem and then it kind of like, they ran it, you could see the output, it realized that the output, it wasn't even that, I don't think it ran into any like compile issues or something, it ran successfully, but the output was just like nonsensical. And so it like logically reasoned that there must be a mistake somewhere in like the program. So I don't know how, I actually don't know how kind of like Copilot did that, but I would imagine the way that I think like, I think the best way, I think hard coding, like, oh, check if error, check this, I think that is doomed for failure because I think that's just, you're going to run into too many edge cases. And so I think actually the right way to go about this and the way that people will go about this in the future is basically letting the, basically telling the language model that it can take these actions. It can write code, it can run code, it can observe output of code, or I guess in the case of SQL, it can write SQL, it can run SQL, it can observe the output of SQL, it can check SQL query or something like that. And then basically let it determine like what actions it should take. So first it should write some code, then it should run the code, then it needs to look at the output and then it determines, okay, do I need to like edit the code? Do I need to run it again? Can I return it to the user? And so basically like, yeah, I think the control flow will kind of like be determined by the language model, but then it just has access to all these like tools or actions, whatever you want to call them, where it can do certain things. But it's not hard, it's not hard, it's like, it's not hard coded that like you do this, then you do this, then you do this. I just think that will not enable the types of experiences that are needed for these more kind of like complex workflows. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "Yeah, because I think what Bob was saying earlier with the idea of you spin up a pod and it knows how to monitor the production app. I haven't learned too, I didn't know too much about this until I joined Weaviate and got under the curtain and saw all the things that happen. And it's like that idea of the language model, keeping the software running with all the errors that come up, that is just amazing, I think. ",
        "podNumber": 36
    },
    {
        "speaker": "Bob van Luijt",
        "content": "Yeah, exactly. And to build on top of that, so I'm just curious to see if it would go to a world where, so as you're describing it Harrison, I think that will of course be like the short term, not even tomorrow, like right now, like we describe something, what we see with Copilot, we describe a problem, it outputs SQL, and then it gets whatever it needs from the database, right? But I wouldn't be surprised if we're going to skip that middle step at some point. So let's take Weaviate as an example. There's no reason why Weaviate couldn't have like a SQL interface, we don't have that, but you could theoretically have that. That if you just have like a situation where it's like, okay, we have like, this is how the embeddings are encoded on disk or in memory and those kinds of things, and then the model just knows where to get it. And that we get just new systems that would just interact with them based on that, it just knows where the information is, and it just figures that out by just telling it in the prompt, right? So literally prompt engineering, like, this is how the database is structured, this is how we store the vectors and the data in memory or on disk, do your thing, right? And I wouldn't be surprised if you see that, not tomorrow, but like, I would be surprised if very soon we will see the first maybe research or blog post and people experimenting with this. So just to cut out the middleman, basically, where the middleman is the interface language, like SQL or those kind of things, because the problem is that these interfaces, they force us to be extremely hyper structured, which is understandable and which is great for many use cases. But what if you can just skip that altogether? Because the way that we're now interfacing with each other, right, I'm not formatting my questions or my remarks in a certain way that I go like, okay, I hope that Connor can parse what I'm saying right now, right? I just use language. And then it just, you know, and I really hope that that is where we can go based on these embedding based and language model based approaches. I mean, this is a little bit further than the future, but I really hope that we can get there, you know, with all these tools and what everybody's working on. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "Yeah. So Harrison, can I ask about some of the prompts that you like the most? Like maybe like, let's think step by step, the idea of you are the writer, you are the editor, you are the reviewer, like have any of these prompts really stood out to you as being really interesting?",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "Yeah, I think the ones that are most interesting to me are the ones that are good, are basically good at interacting with arbitrary external kind of like tools. And so what I mean by that is like, so okay, interacting with like external tools and thinking about how to like reason with tools, there's a really good paper called React, which is like synthesizing reasoning and acting. And basically it combines kind of like some of the chain of thought stuff, which is where you kind of like ask the language model to kind of like think slowly about what it, you basically tell it to think, which sounds silly, but you tell it to think. And then acting is like determining kind of like what action to take and what action and what input to that kind of like action or tool to be. And so combining them, it kind of, you know, I think the paper showed some pretty nice gains and a bunch of benchmarks and stuff like that. So that type of prompting is really interesting to me, because I think having the language model act as kind of like a conductor that can interact with things is very powerful. And so any type of prompting that enables that, I really like. Now taking like the zero shot kind of like thing to that. So the original paper kind of like hard-coded a bunch of few shot examples. So they gave it a bunch of, so I think like in the original paper, one of the examples was interacting with like the Wikipedia client. And so it could do like a search, it could do like a lookup. I think those were the two actions it could do. It gave a bunch of examples of it doing those actions. And then it learned from those examples. And so to the point earlier about like prompt engineering, kind of going the way of you just tell it what to do. Like, I think the way that it will be in the future is you won't necessarily have to give it those examples. You can just tell it like, this is what you can do. And so the zero shot way of interacting with tools is exactly that. There's no examples. You just kind of say, hey, you have access to this tool. It's called search. It takes as input a string. And what it does is it look, and you should use it for like current events and stuff like that. And then you do that with however many tools you have. And it kind of just like learns to use them in a zero shot way. And the React prompting is really powerful for this because it lets it like think about like, you know, all the information it has, like the tool name and the tool description and stuff like that. And I find this really cool. And I think yeah, one, it like works surprisingly well, just out of the box. And then the other like really fun thing is that if it's not working, it's kind of easy to tweak by just like changing the description of the tool. So one of the common questions I get asked is like, how can I like, you know, it's using this tool incorrectly, or like, how can I get it to use this tool in this specific scenario? And it sounds stupid. But the answer is you just tell it to like, you just tell the language model, like, use this when you have a question about math, use this when you have a question about music. And it's generally pretty good at like, observing that and following those instructions. And so that type of like zero shot React prompting is that's that's by far the most interesting stuff to me, I think. ",
        "podNumber": 36
    },
    {
        "speaker": "Bob van Luijt",
        "content": "Very exciting. Very exciting. I just I just want to highlight one more time that when you said like, you just tell it to that is just how far we got like in like, just think about two years ago, right? It's that is just that that one sentence there, you just tell it that was like, how exciting that is. I love that. ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "Yep, yeah. All in all the papers, you know, a lot of the papers that came out in this were from like, I mean, yeah, even like a year ago, when you needed few shot examples, and you couldn't just tell it to and you had to do this, like really elaborate prompt engineering. And now you just kind of like tell it to and there's still like, again, like, I don't think this I don't think this means that there's no need for prompt engineering, like you still have to, like, figure out how to like, you still have to construct the prompt in a certain way. And you still have to tell it like what scenarios it's good for and stuff like that. But it's a lot easier to and it's just like, it's more similar to just chatting with a human and instructing. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "Yeah, I think maybe playing the devil's advocate here, I think kind of the you just tell it to is maybe like, I think the whole thing about prompt engineering is that there is a little bit of an art to telling it right, like, and so I'm really curious about this intersection between, like, you could sample many decodings from the large language model, that temperature thing being like the key knob that you can slide. Maybe firstly, just to set the stage, what do you think about that temperature parameter on the large language models? ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "I think if I'm so I think there's two different like ways to use language models, I would say one is like leveraging their like reasoning ability, and their ability to like, you know, yeah, take ambiguity and decipher and decide what to do. And this comes into a lot of the action stuff. And then the other is generating text, right, generating prose generating poems. So for the latter, for like generating text, yeah, crank the temperature up, like get some like funky responses, go for it. But for like the part where you want to like reason about things, I almost always set like temperature to zero. And just because you want the single kind of like you want the best, most accurate response. ",
        "podNumber": 36
    },
    {
        "speaker": "Bob van Luijt",
        "content": "Yeah, that's it's interesting that you say that because the what we're also seeing with the database, right, so and Connor and I coincidentally earlier today had a conversation about that, that what I really believe is like you have like the reasoning aspect of the model. And then in our case, also the database, right, so we say that you can say, okay, we're going to literally in prompt engineering, you tell it like we're going to give you information in this format. And you must base your answer on the information we're giving it. And if you can't tell us you can't, and then temperature all the way to zero. You know what I mean? And I find it very interesting, because what that means is that you're kind of cutting out, and I'm air quoting it, the knowledge that is in the model, but you keep it to the language understanding, like as if you have like a human who just understands everything you're saying, but has no knowledge, and has like an old set of, you know, encyclopedias. And then you go like, okay, what's the distance from Earth to the moon? And okay, I understand the question. Let me find that in the encyclopedia. And I find that very intriguing. And I'm curious, I have a question for you about this, Harrison. So there are like two camps, right, that we see. Like one is like we're going to keep fine-tuning the model until it has all the knowledge, right, for whatever use case we have. Or we're going to just keep that separation that we say like we have the model, and we just feed it with data coming from a data source. I'm just curious where, I mean, I have strong opinions on this, but I'm very curious where you sit on this, you know, what your angle is, and what your take is on these approaches. ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": " (stopped at 33:23)Yeah, I mean, I think there's, honestly, I think there's like a place and time for both. I don't think that one's kind of like strictly better than the other. I think the one that's more interesting to me is kind of like the one that you combine with external data. I think, but like, you know, if we think about that language model is kind of like acting as a decision maker or a router, one of the things that it could route to is a larger language model that is trained on everything. And it could call that like when it needs to. But yeah, I think the idea of fine tuning on everything and always trying to make sure the language model is up to date, I'm not very bullish on that. I do think there's a place for like general purpose language models, but as I said, I'd rather use that as like a tool rather than trying to like have that be the sole source of everything. And then yeah, like combining data with language models, I think there's, I mean, even today you can do that with prompt engineering. There's some like really interesting papers on like kind of like ways to do it at a more kind of like more native to the model. So where you're actually attending over embeddings of documents that you pull. So like retro style approaches. I don't think there are any great publicly available models for that yet, but that might be something that comes out in the next year or two that would be really interesting. And then yeah, the idea of having like the language model act as a router. One thing that I like, I would love to have like a fine tuned model that's just really good at zero shot kind of like routing and reasoning. And I'm actually chatting with a few folks by this, so I don't know when this is coming out. So it's possible that when this comes out, we'll have some like, yeah, we'll have already shared some stuff about that. But like, I think creating that like small fine tune model really good at zero shot reasoning would be really, really cool. And so yeah, that's kind of the, that's the type of fine tuning that I'm interested in. I'm not interested in kind of like the fine tuning to make it kind of like up to date with every possible information that's under the sun. I'm more interested in kind of like the fine tuning to have it do routing to other sources of information.",
        "podNumber": 36
    },
    {
        "speaker": "Bob van Luijt",
        "content": "Yeah, I like that very much. So I have a very similar point of view. So I would not be surprised if we're going to see these kind of models that are just, that indeed are like good at like general purpose things, like an LLM for medical terminology, an LLM for legal terminology, an LLM for engineering, those kind of things. But that it is very good at just processing, have basically these one shot approach, right, that you mentioned that it just, it understands like, for lack of a better term, so it understands it can help you reason what kind of data that it needs to get from, in this case, a database or any data source that you give it. So it's, it's interesting to say that because I have a very similar point of view. Yeah. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "Yeah. I think I used to really like this idea of like, you would maybe have some kind of classifier that classifies the model in the Hugging Face model hub. That's the best for this task. But so, so what will this, all of these large language models, the lawyer, the biomedical language model, how do you see, like, how will that be organized?",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "First of all, I don't think anyone knows, which makes this so exciting. I think, yeah, I mean, like, I don't know, right now, the private models are way better than the open source models. Like, I think it's, yeah, like, you know, GPT, GPT-3 is way better than the best open source models, probably Flan-T5. Anthropic, when they come out with their model, will probably be pretty good. I think there, you know, it's like, it's possible that there, it's possible there will be a better open source model release. It's possible that to your point around, like, having a model specifically for medical or specifically for law, maybe you can get that by fine tuning Flan-T5. And it's, and it's less about kind of like, you know, maybe for like, smaller, more narrow things like that. Actually, definitely for small, for smaller, narrow things. You can probably get just as good performance by fine tuning Flan-T5 or something like that. First, like, it kind of just depends on like, what small and narrow is, right? Like, is law like small and narrow? I would argue it's still kind of like big and out there, but it's definitely smaller than like, every piece of knowledge under the sun. So, yeah, I don't know. I mean, I guess my current guess would be that they'll be like, the private models will be the best general purpose models, the open source models will be fine for smaller tasks. And I think probably over time, like the, like, the open source models will start catching up. And at the same time, the private models will keep on getting better and better. So I think there'll always be this gap, it will just become, like, you know, what's in this gap? Is the real value in this gap? Or is the real value now doable with like, smaller fine tuned models? And I don't, I don't know. I mean, I think it's the real value now doable with like, smaller fine tuned models. And I don't, I don't, I don't know, I don't know how fast those move up a lot, a lot of questions. ",
        "podNumber": 36
    },
    {
        "speaker": "Bob van Luijt",
        "content": "Yeah, actually, now, when you when you put it like that, I'll take back what I said before. So just that you I hope you can cut that out. So I'm joking, but the but the it just let one model, it's just one model to rule them all. And then maybe a few different providers with different, you know, for the edge case, I don't know. But yeah, so this is what I meant, like, what I said, it's like, it's like this traditional mindset, right? So you know, it's like, we have different programming languages for different tasks, but like, why not? Why not one, one model that that does? That's makes sense. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "Yeah, I think the counter argument to that, though, would be like, right now, the inference is kind of expensive, like compared to if I train like an extractive QA model on my documentation, like it, you know, I could even sparsify the question answering model, it maybe is only like 80 million parameters. And so it's just super fast. That would be kind of my counter argument to like the smaller fine tune models for certain tasks, like in the search pipeline, like the re ranker, like I see a lot of tweets that are like, oh, you can use the large language model to re rank. And I'm like, what a waste of the large, like, to re rank is kind of it. ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "I think the paradigm and there's a good quote from Stan from dust, and so I'm going to shamelessly steal it here. But he has a great quote. That's like, no GPUs before PMF, which is basically like no GPUs, no fine tuning of models before PMF product market fit before you know what you're doing. And I think like, the power of large language models is that they're so good as just like arbitrary tasks, and you can get them to do like, basically whatever. And so experimenting with like different pipelines or different things that you're doing is really it's it's so much easier than before. And so I think the common thing will basically be like, you know, experiment with the best models, then when you actually get something that's like working, and you want to scale it up, not even that's like what like, when it's working, and it's just for you, it's probably fine. But when you want to like scale it up, then you need to worry about like fine tuning models. And so I think it's also kind of like a progression as well. Like, you know, if I if I was building an application, I would never start with a fine, I would never start with fine tuning. No, I'd start with the language model. And then when I start with the biggest language model, GPT-3 or something like that. And then when, yeah, when when, when I get to the point where I have enough confidence that I need to scale it up, then I'd start thinking about that. And I think that'll be like a pretty common workflow. And I've already seen a few people in Yeah, I've already seen a few people like doing that. It's, it's not that crazy, right? ",
        "podNumber": 36
    },
    {
        "speaker": "Bob van Luijt",
        "content": "So no, I just want to say that's very, that's very interesting. And especially with what you said with PMF, right? The product market fit, it's like, there's this tipping point of like, with the models being the general purpose models are good enough to solve the task, right? So it just, and we're just we're hitting that tipping point. I found it fascinating to what we saw the last few weeks, that discussions on Twitter and what have you and in newspapers, I was just sitting on the side eating popcorn while I was watching it, right of seeing like core research, but also like product people working in this space, how they look at this very differently, right? So it's like, and I think I think that is for me in my profession, one of the breakthroughs of ChatGPT was not only using the model to do it, but also the packaging, like the it's, it's so simple if you think about it, but it's so well executed. And, and that kind of ties into what you were saying, Harrison, that it's, it is it, we're just, we're just past the tipping point that where you can build amazing stuff, like for example, taking Langchain, right, and solve your problem, or store your data in Weaviate and vectorize it and just start searching and do whatever you want to do. That just that is just that has changed in the last year, as opposed to a year before. And that is also why I said earlier, like, I'll take back my what I said, like, maybe it's just going to be like one model, right? Or just a handful of models that are just good enough.",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "Yeah, awesome. So I kind of want to pivot topics and, you know, and ask Harrison a question about sort of the virality of Langchain and the open source engagement has been something that's really been impressive. And so I just want to ask kind of like, like, how the question like, how did you do this? How did you start the fire? Like, obviously, you're a really smart guy. And the idea sticks like crazy. But yeah, like, what are your thoughts on that? ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "Yeah, I mean, I think like, I think like, honestly, I mean, one, it's just been like, so much fun. And I think like, that's the thing with like, all these things. I think Bob was saying, like, it's super easy to like, create these things. Like, it's just so much fun. And people have fun building these things. And I have fun building these things. And so just like, I don't know, there's Yeah, like, I think there's just, there's, there's a lot of like, energy and aspect of fun and just like building things and exploring. And so I don't think like, yeah, like, I think, yeah, like, like, yeah, I don't think I haven't done anything. Like, in particular, it's just been like, a lot of fun. I think like, yeah, I mean, like the, you know, the, the, the two things that I try to focus on, besides just having fun, although they are like, very related, or like, build, like, actually useful things, and then like, be nice as well. Like, I think like, and that gets back into like, having fun, right? Like, I think like, there really is just like, everyone's, like, this is a great time to be hacking on like, ideas and be exploring ideas, right? This is a phenomenal point. And like, you know, yeah, like, I'm not that old. But like, this is by far the best point in my lifetime for like, exploring these types of ideas. And so and I think a lot of people realize that. And I think a lot of people are out there doing that. And so just like trying to build things that are actually useful for them. And then like, you know, like, be nice and having fun with people as they're doing it. Like, I think, you know, yeah, no, no, that's, that's all I really got. So. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "Yeah, that's incredible. And I think just like, yeah, exactly, like the contagiousness of sharing Oh, this prompt sequence created this is Yeah, and it is really, truly amazing. So I'm kind of curious to see like the Langchain hub. So what are kind of the directions? Are you thinking of taking my chain? ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "Yeah, I mean, I think like the to your point around basically, like sharing this prompt sequence sharing, that's exactly what link chain hub is designed to do. I think we put something out really quickly in like a GitHub repo, where it's just a collection of kind of like chains and agents and prompts that you can easily load and prompts you can't really use by themselves, but like chains and agents, you can just easily load and use by themselves. And I think the, despite it being a terrible UX, as like, you know, GitHub repos are great, don't get me wrong, but they're not meant for like sharing and discoverability and stuff. And so like within a particular GitHub repo. So despite that terrible UX, like I think we saw a lot of people really interested in it. And so I think that's something that we're, you know, and I think like, like, why are people interested in this, because like, there, there's just so many different things that you can do with them. And so like having them, like, and, and, again, going back to like the just like, hacking and building and playing around, like, there's definitely that type of like atmosphere. And a big part of that is like sharing your work. And so they're like, not just link chain is open source, but a lot of other really awesome projects built on top of it are open source. And so like the idea of like sharing, I think people really enjoy and like, and LangChain Hub is really just aimed at making it easy to share your, your chains, your agents, your prompts, stuff like that. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "Yeah. So maybe, yeah, like the, the open source thing is really fascinating. Like the, how has kind of the maintenance been of it as, cause I understand, like how many, are you the sole maintainer or how does that kind of thing happen? ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "Yeah. So there's one other person working on it full time with me. The maintenance costs have definitely gone up. I'm not gonna lie. I think there's like, yeah, I think there's like 110 GitHub issues and like 43 open PRS. So I've got to catch up on that a little bit for sure. But honestly, like, I think it's been, but like, it, but it, but it's been like fun. Like it's, it's like all the things that people are adding are like, you know, like people are adding like different, different kinds of like embedding modules, different types of, of model providers. Like there's like that I hadn't even heard about, but like now I'm like, okay, I got to go check that out. Like different types of like vector stores, different types of chains, different types of, of, of tools to like interact with. And so I think like even though there's a lot of issues, I mean, and someone like opened up a PR for like some of like the image stuff. Right. So it's like I don't know, like, even though there's a bunch of stuff and there's a little bit of a backlog, which I need to, I need to fix right after this. But yeah, it's, it, it hasn't been like too laborious to kind of like keep up with or anything like that. ",
        "podNumber": 36
    },
    {
        "speaker": "Connor Shorten",
        "content": "Awesome. Well, fantastic Harrison, I'll let you get back to it. I thought this was such an incredible, such an incredible podcast. I mean, yeah, the sequential chains is the first thing that just helped me instantly get it. So if listeners are out there wondering, checking LangChain out for the first time, you know, the sequential chain of how you chain together multiple language protocols, one to the Weaviate vector database. And yeah, I think it's just such a fascinating library and seeing it emerge. So Harrison, thank you so much for your time and joining the Weaviate podcast. ",
        "podNumber": 36
    },
    {
        "speaker": "Harrison Chase",
        "content": "No, thank you guys for having me. And yeah, just, I don't know if people listening to this realize, but like Weaviate and you in particular, Connor reached out super early on in the LangChain journey. Like, I don't, like it was, it was, yeah, like I, yeah, that was a while ago and it's been awesome to kind of like work with you guys and kind of like, I think we both see the world in like similar ways and there's a lot, like I think vector stores are like for a lot of applications are like a critical enabling piece. And so it's been awesome to work with you guys and chat about stuff. And so, yeah, thanks for it. Thanks for having me on. Always, always happy to do it. ",
        "podNumber": 36
    },
    {
        "speaker": "Bob van Luijt",
        "content": "Yeah, thank you. It's super exciting. And you know, we're here to help each other because it's just a whole new ecosystem. That's like, it's like a supernova, like, you know, thanks to these LMs and like this whole new ecosystem. And we're just, I think we need to help each other, right. To reach our goals. And this is just, yeah, this is super exciting.",
        "podNumber": 36
    }
]